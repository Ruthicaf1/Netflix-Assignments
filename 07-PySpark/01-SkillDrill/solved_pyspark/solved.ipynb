{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKJ9CI8UZHgk",
        "outputId": "f8844a37-c452-4a67-ed1d-a60609a1ee35"
      },
      "source": [
        "# activate Spark in our Colab notebook.\n",
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.1.1'\n",
        "# spark_version = 'spark-3.<enter version>'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [52.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,045 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,402 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,749 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,475 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [895 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,170 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [39.5 kB]\n",
            "Fetched 11.1 MB in 3s (3,507 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2GAwS6CaVbm"
      },
      "source": [
        "#import packages\n",
        "# We are using pandas to read the raw csv files from github, then converting them to spark Dataframes (this will save us some download time and HDD space on our laptops)\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType\n",
        "import pandas as pd\n",
        "# we are going to use this to time our queries.\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckUsz6PIae4m",
        "outputId": "e440cff8-c1fd-48f4-e23c-5fd4b024b066"
      },
      "source": [
        "# Read in data\n",
        "from pyspark import SparkFiles\n",
        "peter_p_df = spark.read.text(\"peterpan.txt\")\n",
        "peter_p_df.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|All children, exc...|\n",
            "|Of course they li...|\n",
            "|The way Mr. Darli...|\n",
            "|Mr. Darling used ...|\n",
            "|Mrs. Darling was ...|\n",
            "|Wendy came first,...|\n",
            "|For a week or two...|\n",
            "|“Now don't interr...|\n",
            "|“I have one pound...|\n",
            "|“Of course we can...|\n",
            "|“Remember mumps,”...|\n",
            "|There was the sam...|\n",
            "|Mrs. Darling love...|\n",
            "|No nursery could ...|\n",
            "|He had his positi...|\n",
            "|Nana also trouble...|\n",
            "|Mrs. Darling firs...|\n",
            "|I don't know whet...|\n",
            "|Of course the Nev...|\n",
            "|Of all delectable...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZoCt9V2b1BD"
      },
      "source": [
        "peter_p = spark.sparkContext.textFile(\"peterpan.txt\")\n",
        "#splitting the words\n",
        "peter_p_splitting = peter_p.flatMap(lambda line: line.split(\" \"))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyAqlswgeTz8"
      },
      "source": [
        "#counting of words\n",
        "peter_pan_count = peter_p_splitting.map(lambda word: (word, 1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BocOatMyellx"
      },
      "source": [
        " #adding the count of each word in each line\n",
        "from operator import add\n",
        "peter_pan_count_all = peter_pan_count.reduceByKey(add)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCT3UbN8ey1d"
      },
      "source": [
        "peter_pan_count_all.saveAsTextFile('output_Counts.txt')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p38j2oXQfA1z",
        "outputId": "9d6e87b3-d2b3-42e2-a3f9-d247c17a410c"
      },
      "source": [
        "spark.read.text('output_Counts.txt').show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+\n",
            "|         value|\n",
            "+--------------+\n",
            "|  ('one,', 15)|\n",
            "| ('They', 101)|\n",
            "|  ('know', 64)|\n",
            "|   ('way', 58)|\n",
            "|  ('was', 897)|\n",
            "|    ('One', 9)|\n",
            "| ('when', 151)|\n",
            "|   ('two', 36)|\n",
            "|  ('years', 3)|\n",
            "|   ('in', 623)|\n",
            "|('garden,', 1)|\n",
            "|('plucked', 2)|\n",
            "| ('flower', 2)|\n",
            "|   ('ran', 17)|\n",
            "|  ('her', 361)|\n",
            "|('suppose', 7)|\n",
            "|  ('must', 59)|\n",
            "| ('have', 243)|\n",
            "|('looked', 33)|\n",
            "|('rather', 40)|\n",
            "+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}